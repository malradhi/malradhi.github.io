<!DOCTYPE html>
<html><head>

 
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="chrome=1">
        <title>malradhi</title>

        <link rel="stylesheet" href="css/styles.css">
        <link rel="stylesheet" href="css/extra_min_styles.css">
        <meta name="viewport" content="width=device-width">
        <!--[if lt IE 9]>
        <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
        <![endif]-->

        <!-- Icons -->
        <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
        <link rel="stylesheet" href="https://i.icomoon.io/public/temp/57136724af/UntitledProject/style-svg.css">

        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script type="text/javascript" async="" src="https://ssl.google-analytics.com/ga.js"></script><script>
          var _gaq = _gaq || [];
          _gaq.push(['_setAccount', 'UA-118294862-1']);
          _gaq.push(['_trackPageview']);
          
          (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
          })();
        </script>
    </head>

    <!-- ALL CONTENT -->	
	
    <body data-new-gr-c-s-check-loaded="14.1012.0" data-gr-ext-installed=""><div class="wrapper">
    <!-- BODY -->
    
    <!-- HEADER -->	
    <header>

        <h2 align="middle">Dr. Mohammed Salah Al-Radhi</h2>
		

        <!-- Picture + Links + News -->
        <div align="middle" style="margin-bottom: 10px">
			

            <!-- Portrait -->
            <img src="images/malradhi_3.png" alt="Portrait" WIDTH=100 style="margin-bottom: 8px;border-radius: 24px;">
            <!-- <img src="https://david-abel.github.io/images/portrait.JPG" alt="Portrait" class="portrait"> -->

            <!-- Email -->
            <!-- <div style="margin-bottom: 6px;"><img src="images/e.jpg" width="175"></div> -->
			
			<!-- Email -->
			<h3>Research Scientist | Artificial Intelligence</a></h3>
			<!-- <h5><a><b>malradhi@tmit.bme.hu</b></a></h5> -->

            <!-- CV -->
            <a href="pdf/cv_malradhi.pdf" target="_blank"" onclick="_gaq.push(['_trackEvent', 'Click', 'CV Clicked']);" style="margin-right:14px;"><i class="ai ai-cv" style="font-size: 32px;"></i>
            </a>
			
            <!-- RG -->
            <a href="https://www.researchgate.net/profile/Mohammed_Al-Radhi2" target="_blank" onclick="_gaq.push(['_trackEvent', 'Click', 'ResearchGate Clicked']);" style="margin-right:14px;">
                <i class="fa fa-researchgate" style="font-size:32px;">R<sup style="font-size:18px;">G</sup></i>			
            </a>			
			
			

            <!-- Scholar -->
            <a href="https://scholar.google.com/citations?user=cUq-wkMAAAAJ&hl=en&oi=ao" target="_blank" onclick="_gaq.push(['_trackEvent', 'Click', 'Scholar Clicked']);" style="margin-right:14px;">
                <i class="ai ai-google-scholar big-icon" style="font-size:33px;"></i>
            </a>



            <!-- ORCID -->
            <a href="https://orcid.org/0000-0003-3094-6916" target="_blank" onclick="_gaq.push(['_trackEvent', 'Click', 'ORCID Clicked']);" style="margin-right:14px;">
                <i class="ai ai-orcid" style="font-size:32px;"></i>
            </a>

			
   
			
		</div>
		
	


	
		<div align="middle" style="margin-bottom: 10px">

		

            <!-- Git -->
            <a href="https://github.com/malradhi" target="_blank" onclick="_gaq.push(['_trackEvent', 'Click', 'git Clicked']);" style="margin-right:14px;">
                <i class="fa fa-github" style="font-size:32px;"></i>
                <!-- color: #A7A499" -->
            </a>



            <!-- Scopus -->
            <a href="https://www.scopus.com/authid/detail.uri?authorId=57195671347" target="_blank" onclick="_gaq.push(['_trackEvent', 'Click', 'Scopus Clicked']);" style="margin-right:14px;">
                <i class="fa fa-scopus" style="font-size:32px;">Sc</i>
            </a>




            <!-- LinkedIn -->
            <a href="https://www.linkedin.com/in/10malradhi/" target="_blank" onclick="_gaq.push(['_trackEvent', 'Click', 'LinkedIn Clicked']);" style="margin-right:14px;">
                <i class="fa fa-linkedin" style="font-size:32px;"></i>
				
            </a>	
			
			
            <!-- Twitter -->
            <a href="https://twitter.com/10malradhi" target="_blank" onclick="_gaq.push(['_trackEvent', 'Click', 'Twitter Clicked']);" style="margin-right:14px;">
                <i class="fa fa-twitter" style="font-size:32px;"></i>
            </a>
						
			
			
	
            <br>
            <br>
        </div>


    <!-- Put "nav" here for side bar nav -->
        <ul class="navbar">
            <li class="navbar_li"><a href="index.html">Home</a></li>
            <!-- <li class="navbar_li"><a href="index.html">Teaching</a></li> -->
			<li class="navbar_li"><a href="#Supervising">Supervising</a></li>
			<li class="navbar_li"><a href="#Teaching">Teaching</a></li>
			<li class="navbar_li"><a href="#Projects Activity">Projects</a></li>
            <!-- <li class="navbar_li"><a href="collaborators.html">Collaborators</a></li> -->
			<li class="navbar_li"><a href="#Full Publications">Publications</a></li>
			<li class="navbar_li"><a href="mailto:malradhi@tmit.bme.hu">Contact</a></li>
        </ul>


    </header>

      <!-- BODY -->
	     
		
    <section>
		

            <br>
            <br>

			
        <h2>Biography</h2>
				
		<p style="font-size:16px">Dr. Al-Radhi is a Research Scientist at <a href="https://www.bme.hu/?language=en" target="_blank">BME-VIK-TMIT</a> in Budapest, Hungary, actively contributing to the realization of impactful European projects like the <a href="https://ec.europa.eu/info/funding-tenders/opportunities/portal/screen/how-to-participate/org-details/999630203/project/101120657/program/43108390/details" target="_blank">ENFIELD</a>, <a href="https://doi.org/10.3030/825619" target="_blank">AI4Europe</a>, and <a href="http://www.aal-europe.eu/projects/aph-alarm/" target="_blank">APH-ALARM</a> projects. With a PhD in Artificial Intelligence of Speech from the BME, Dr. Al-Radhi specializes in accurately designing high-quality vocoding mechanisms, utilizing advanced signal processing techniques for speech synthesis and voice conversion applications. In education, he provides scholarly guidance to PhD, MSc, BSc students, directs their theses and projects, and imparts knowledge in courses covering deep learning, info-communication, human-computer interaction, and smart city laboratory. Dr. Al-Radhi is an esteemed reviewer for distinguished top-tier journals and conferences. His leadership role as a special issue editor for the prestigious Journal of Electronics reflects his elevated standing in the academic community. Recognized for his solid commitment to scholarly excellence, Dr. Al-Radhi has received honours, including a PhD dissertation defense with the highest distinction and a prestigious M.Sc. award. His impactful publications span diverse domains, featuring seminal research on nonparallel expressive TTS, child-based speech, and pioneering advancements in voice cloning and conversational AI.</a></p>
       
        <!-- <p style="font-size:16px">Dr. Al-Radhi received a B.Sc. degree in Computer Engineering at <a href="https://en.uobasrah.edu.iq/" target="_blank">Basra University</a> in 2007, and a M.Sc. degree in Communication Systems Engineering at <a href="https://www.port.ac.uk/" target="_blank">Portsmouth University</a>, UK which was achieved with first-class honours in 2012 and awarded the MSc top student certificate in 2013. He received his Ph.D. from the Faculty of Electrical Engineering and Informatics at the Speech Technology and Smart Interactions Laboratory in <a href="https://www.bme.hu/?language=en" target="_blank">Budapest University of Technology and Economics (BME)</a>, Hungary in 2020, where he obtained it with honour (100%) and summa cum laude. Since October 2020, he was a postdoctoral researcher fellow in the <a href="https://www.tmit.bme.hu/?language=en" target="_blank">Department of Telecommunications and Media Informatics (TMIT)</a>, BME, Budapest. He has participated in some research projects including the <a href="https://www.ai4europe.eu/">AI4Europe</a> (building a European AI on-demand platform) by taking part in the adaptation of the BME TMIT SmartLab developed vocoder, and <a href="http://www.aal-europe.eu/projects/aph-alarm/">APH-ALARM</a> (comprehensive safety solution for people with Aphasia) with a TTS system to guide users through the options of calling for help. He served as a reviewer for several top-tier journals and conferences proceedings. Currently, he served as an editorial-board member for the journal of Electronics (IF 2.412, ISSN 2079-9292). His main interests are Artificial Intelligence and Machine Learning in speech signal processing and voice conversion</a>.</p> -->
            <br>
            <br>


		<hr>
		
        <!-- NEWS -->
        <h2>News</h2>
            <ul>
                <!-- <li style="font-size:16px">March 7, 2021: joined the Editorial Board as Topic Editor in the journal of <a href="https://www.mdpi.com/journal/electronics">Electronics</a>.</li> -->
				<li style="font-size:16px">I have been awarded the <b>BME EKÃ–P Program</b>. This funding will support my research on <b>Brain-Computer Interface</b>, starting from September 2024.
				
				<li style="font-size:16px">accepting new <b>PhD students</b> interested in AI. Explore available topics in <a href="https://doktori.hu/index.php?menuid=139&lang=EN&sz_ID=22723&elo=1" target="_blank">doktori platform</a> and reach out via email if interested!</li>
				<li style="font-size:16px">leading a Special Issue entitled <a href="https://www.mdpi.com/journal/electronics/special_issues/847MLDA3C8" target="_blank">New Insights and Techniques for Neural Networks</a>. It focuses on the modern machine learning techniques to natural process modeling and related decision-making. The submission deadline is <b>15 November 2023</b>.</li>
				<!-- <li style="font-size:16px">June 2, 2021: <b>Wavelet vocoder</b> got accepted for publication to <a href="https://www.interspeech2021.org/" target="_blank">Interspeech 2021</a>.</li> -->
				
			<!-- 	
                <li>April 20, 2021: New preprint out on <a href="https://arxiv.org/pdf/2103.00107.pdf">Pengâ€™s Q(Î»)</a>, led by <a href="https://tadashik.github.io/">Tadashi Kozuno</a> and <a href="https://robintyh1.github.io/">Yunhao Tang</a>.</li>
                <li>February 24, 2021: Guest lecture in <a href="https://iacs.seas.harvard.edu/people/chris-tanner">Chris Tanner's</a> capstone <a href="https://www.capstone.iacs.seas.harvard.edu/">course</a> at Harvard.</li>
                <li>December 9+16, 2020: Talk(s) in <a href="http://grla.wikidot.com/frl">GRLA</a>.</li>
                <li>December 2, 2020: <a href="papers/aaai2021_lipschitz.pdf">Lipschitz Lifelong RL</a> accepted to AAAI.</li>
                <li>October 5: I joined DeepMind London as a Research Scientist.</li>
                <li>September 30, 2020: I gave a guest lecture in <a href="https://iacs.seas.harvard.edu/people/chris-tanner">Chris Tanner's</a> capstone <a href="https://www.capstone.iacs.seas.harvard.edu/">course</a> at Harvard.</li>

                <li>September 22, 2020: I moved to London.</li>
                <li>August 25, 2020: <a href="https://david-abel.github.io/blog/posts/vpsa_aistats_2020.html" onclick="_gaq.push(['_trackEvent', 'Click', 'ais blog post (news) Clicked']);">New blog post</a> with collaborators summarizing our AISTATS <a href="https://david-abel.github.io/papers/aistats2020_vpsa-full.pdf" onclick="_gaq.push(['_trackEvent', 'Click', 'ais bp (news) Clicked']);">paper</a>.</li>
                <li>June 26, 2020: New ICML <a href="https://arxiv.org/pdf/2006.15085.pdf" onclick="_gaq.push(['_trackEvent', 'Click', 'icml aff (news) Clicked']);">paper</a> out on affordances in RL.</li>
                <li>April 27, 2020: My <a href="https://david-abel.github.io/thesis.pdf" onclick="_gaq.push(['_trackEvent', 'Click', 'Thesis (a) Clicked']);">dissertation</a> is done!</li>
                <li>April 7, 2020: I defended my thesis.</li>
                <li>March 1, 2020: New AISTATS <a href="https://david-abel.github.io/papers/aistats2020_vpsa-full.pdf" onclick="_gaq.push(['_trackEvent', 'Click', 'ais full (news) Clicked']);">paper</a> out on state-action abstraction.</li>

                <li>December 15: <a href="https://david-abel.github.io/notes/neurips_2019.pdf" onclick="_gaq.push(['_trackEvent', 'Click', 'NeurIPS 2019 Notes Clicked']);">Notes from NeurIPS 2019 available</a>. </li>
               
                <li>December 8-14: At NeurIPS to give a talk (<a href="https://drive.google.com/file/d/19YHF48r_qK3Wb6ULqI5K6XcwviZ0U1lz/view?usp=sharing">slides</a>, <a href="https://slideslive.com/38921884/metalearning-3">video</a>) at the <a href="http://metalearning.ml/2019/">Meta-Learning workshop</a> .</li>
 -->

            </ul>

            <br>
            <br>
						

		<hr>
		
        <!-- Academic Employment -->
        <h2>Academic Employment</h2>
            <ul>
                <li style="font-size:16px">Oct 2020 - 2023
				  <ul>
                    <li>Postdoctoral Fellow, <a href="https://www.tmit.bme.hu/?language=en" target="_blank">BME-VIK-TMIT</a>, Budapest, Hungary</li>
					<!-- <li>Teaching and Supervison</li> -->
                  </ul>
				</li>


                <li style="font-size:16px"> 2024 - present
				  <ul>
                    <li>Research Scientist, <a href="https://www.tmit.bme.hu/?language=en" target="_blank">BME-VIK-TMIT</a>, Budapest, Hungary</li>
					<!-- <li>Teaching and Supervison</li> -->
                  </ul>
				</li>  




				
            </ul>
		
            <br>
            <br>
								
		

		<hr>
		
		<div id="Projects Activity">
		
        <!-- Projects Activity -->
        <h2>Projects Activity</h2>
            <ul>
                <li style="font-size:16px"><a href="https://www.enfield-project.eu/" target="_blank">ENFIELD</a>: European Lighthouse to Manifest Trustworthy and Green AI. 
					<ul>
						<li>2023-2026, Researcher, European Horizon 2020 Commission <a href="https://doi.org/10.3030/101120657" target="_blank">(doi)</a></li>
					</ul>
				</li>
				
				
				
				<li style="font-size:16px"><a href="https://www.ai4europe.eu/" target="_blank">AI4Europe</a>: Building a European AI on-demand platform. 
					<ul>
						<li>2019-2022, Researcher, European Horizon 2020 Commission <a href="https://doi.org/10.3030/825619" target="_blank">(doi)</a></li>
					</ul>
				</li>
				
				<li style="font-size:16px"><a href="http://www.aal-europe.eu/projects/aph-alarm/" target="_blank">APH-ALARM</a>: Comprehensive safety solution for people with Aphasia. 
					<ul>
						<li>2020-2023, Researcher, AAL-Europe <a href="https://www.aph-alarm-project.com/index.php/en/" target="_blank">(url)</a></li>
					</ul>
				</li>
				
				
				<li style="font-size:16px"><a href="http://nyilvanos.otka-palyazat.hu/index.php?menuid=930&num=124584&keyword=124584&lang=EN" target="_blank">OTKA-FK-124584</a>: Silent Speech Interface based on articulatory movements. 
					<ul>
						<li>2017-2022, Investigator, Hungarian Fund <a href="https://nkfih.gov.hu/english-nkfih" target="_blank">(url)</a></li>
					</ul>
				</li>				
				
				
				
				
				
            </ul>
			
			</div>
		
            <br>
            <br>
								
		

		<hr>


        <!-- INTERESTS -->		
		
        <h2> Research Interests </h2>
		
		
	     <p style="font-size:16px">
        	My research focuses on applying advanced artificial intelligence and machine deep learning to push the boundaries of speech and language processing. Currently, my focus includes developing expressive speech synthesis, cutting-edge Text-to-Speech systems, innovative voice cloning methods, and exploring conversational AI. Additionally, I delve into Explainable AI (XAI), contribute to the fake voice detection and enhancing voice authenticity verification.
       	</p>
		
		
        <br>
        <br>
		
		
		<hr>







		
        <!-- Education -->
        <h2>Education</h2>
            <ul>
                <li style="font-size:16px">Sep 2016 - Sep 2020 
					<ul>
						<li><b>Ph.D. (100%, hons, summa cum laude)</b> in Artificial Intelligence of Speech from faculty of Electrical Engineering and Informatyics at <a href="https://www.bme.hu/?language=en" target="_blank">Budapest University of Technology and Economics</a>, Budapest, Hungary.</li>
						<li>Dissertation title:<a href="https://repozitorium.omikk.bme.hu/handle/10890/13411" target="_blank"> High-quality vocoding design with signal processing for speech synthesis and voice conversion.</a></li>
						<li>My dissertation aimed at developing a vocoder and its role in machine deep learning.</li>
						<li>Supervised by Prof. Habil. <a href="https://scholar.google.ro/citations?user=Qf5PHwoAAAAJ&hl=en" target="_blank">GÃ©za NÃ©meth</a> and Dr. <a href="https://scholar.google.com/citations?user=ivoOEbkAAAAJ&hl=en" target="_blank">TamÃ¡s GÃ¡bor CsapÃ³.</a></li>
						<li>Some photos: <a href="https://malradhi.github.io/images/3.jpg" target="_blank">[1]</a>, <a href="https://malradhi.github.io/images/1.jpg" target="_blank">[2]</a>, <a href="https://malradhi.github.io/images/4.PNG" target="_blank">[3]</a>, <a href="https://malradhi.github.io/images/2.jpg" target="_blank">[4]</a>.</li>
					</ul>
					</li>
            						
				
				<li style="font-size:16px">Sep 2011 - Nov 2012
					<ul>
					    <li><b>M.Sc. (1<sup>st</sup> class, hons)</b> in Communication Systems Engineering from school of Energy and Electronic Engineering at <a href="https://www.port.ac.uk/" target="_blank">Portsmouth University</a>, UK.</li>
						<li>Dissertation title:<a href="https://www.researchgate.net/publication/323801310_Design_of_Finite_Impulse_Response_Digital_Filters_using_Optimal_Methods_MSc_thesis" target="_blank"> Design of Finite Impulse Response Digital Filters using Optimal Methods</a>.</li>
						<li>Supervised by Dr. <a href="https://www.port.ac.uk/about-us/structure-and-governance/our-people/our-staff/branislav-vuksanovic" target="_blank">Branislav Vuksanovic.</a></li>
						<li>My dissertation aimed at designeing a full GUI digital filters depending on the specifications defined by the user.</li>
						<li>Interesting to see Prof. <a href="https://scholar.google.com/citations?user=DDwRY6oAAAAJ&hl=en" target="_blank">Hideki Kawahara</a> in 2017 used various time windowing functions in his <a href="https://www.isca-speech.org/archive/Interspeech_2017/pdfs/0436.PDF" target="_blank">paper related to speech processing</a>.</li>
						<li>Some photos: TODO<a href="https://malradhi.github.io/images/dd" target="_blank">.</a></li>
				    </ul>
				    </li>				
				
				<li style="font-size:16px">Sep 2003 - Oct 2007
					<ul>
						<li><b>B.Sc. (hons)</b> in Computer Engineering from college of Engineering at <a href="https://en.uobasrah.edu.iq/" target="_blank">Basra University, Iraq</a>.</li>
					      </ul>
				    </li>
            </ul>
		
            <br>
            <br>
								


		
		<hr>
		
		
		<div id="Supervising">
		
		<!-- Reviewer -->				
        <h2> Supervising </h2>
		<!-- <p style="font-size:14px"><a href="https://publons.com/researcher/1712405/mohammed-salah-al-radhi/">Publons:</a> WoS ResearcherID C-9727-2018</li> -->
		<tbody>
			<tr>
			    <td>
					<ul>
						<li style="font-size:16px"><b>Main Supervisor</b>
						<ul>
							<li style="font-size:16px">PhD students</li>
								<li style="margin-left:2em; padding-bottom: 0;"><a href="https://scholar.google.com/citations?user=49WZaBcAAAAJ&hl=en" target="_blank">Rammi Kammoun</a>, Tunisian (2024 â€“ 2028)</li>
							
							<li style="font-size:16px">MSc student</li>
								<li style="margin-left:2em; padding-bottom: 0;">Zineb Hammadi, Algerian (2023 â€“ 2025)</li>
								<li style="margin-left:2em; padding-bottom: 0;"><a href="https://scholar.google.com/citations?user=FNq3prEAAAAJ&hl=en" target="_blank">Layan Sawalha</a>, Jordanian (2021 â€“ 2023, <a href="pdf/students/msc_Layan.pdf" target="_blank"> thesis</a>)</li>								

							<li style="font-size:16px">BSc students</li>
								<li style="margin-left:2em; padding-bottom: 0;">Felipe Lopes Franklin Bezerra, Brazilian (2021 â€“ 2022, <a href="pdf/students/bsc_Felipe.pdf" target="_blank"> thesis</a>)</li>
								<li style="margin-left:2em; padding-bottom: 0;">Suciu BarnabÃ¡s, Hungarian (2020 â€“ 2021, <a href="pdf/students/bsc_BarnabÃ¡s.pdf" target="_blank"> thesis</a>)</li>
							
							<li style="font-size:16px">BSc & MSc Project laboratories (2020 â€“ present)</li>
						</ul>
					
					<li style="font-size:16px"><b>Co-Supervisor</b>
						<ul>
							<li style="font-size:16px">PhD students</a></li>
								<li style="margin-left:2em; padding-bottom: 0;"><a href="https://scholar.google.com/citations?user=RsQUGn8AAAAJ&hl=en" target="_blank">Ali Mandeel</a>, Iraqi (2020 - 2024)</li>
								<li style="margin-left:2em; padding-bottom: 0;"><a href="https://scholar.google.com/citations?hl=en&user=Y58CsYwAAAAJ" target="_blank">Shaimaa S. Alwaisi</a>, Iraqi (2022 - 2026)</li>
							<li style="font-size:16px">MSc students</li>
								<li style="margin-left:2em; padding-bottom: 0;">Dean Reymen, Belgian (2021 â€“ 2022, <a href="https://documentserver.uhasselt.be//handle/1942/38262" target="_blank"> thesis</a> in Hasselt University, Belgium)</li>
								<li style="margin-left:2em; padding-bottom: 0;">Pengyu Dai, Chinese (2019 â€“ 2021, <a href="pdf/students/msc_Pengyu.pdf" target="_blank"> thesis</a>)</li>
						</ul>
					


										
<!-- 					<li style="font-size:16px"><b>Delivering teaching sessions on</b>
						<ul>
							<li style="font-size:16px"><a href="https://adatesmi.vik.bme.hu" target="_blank">Deep learning</a> (theoretical lecture)</li>
							<li style="font-size:16px"><a href="https://portal.vik.bme.hu/kepzes/targyak/VITMAB03/en/" target="_blank">Info-communication</a>(theoretical lecture)</li>
							<li style="font-size:16px"><a href="https://portal.vik.bme.hu/kepzes/targyak/VITMMA11/en/" target="_blank">Human-Computer Interaction</a> (practical lecture)</li>
							<li style="font-size:16px"><a href="http://smartlab.tmit.bme.hu/csapo/AR/" target="_blank">Smart City Laboratory</a> (lab)</li>
						</ul> -->
					


					<li style="font-size:16px"><b>Main Examiner for <a href="https://www.vik.bme.hu/document/2306/original/project_lab_20180830.pdf" target="_blank">Project Laboratories</a></b>
						<ul>
							<li style="font-size:16px">Responsible for assessing and assigning grades to BSc and MSc student projects</li>
						</ul>


					</ul>
				</td>
			</tr>
		</tbody>
		
		</div>
		
		<br>

		
		
		<hr>

		<div id="Teaching">
		
		<!-- Reviewer -->				
        <h2> Teaching </h2>
		<!-- <p style="font-size:14px"><a href="https://publons.com/researcher/1712405/mohammed-salah-al-radhi/">Publons:</a> WoS ResearcherID C-9727-2018</li> -->
		<tbody>
			<tr>
			    <td>
					<ul>
						<li style="font-size:16px"><b><a href="https://adatesmi.vik.bme.hu" target="_blank">Deep learning</a></b> (theoretical lecture)
						<ul>
							<li style="font-size:16px">Recurrent Neural Network</li>
							<li style="font-size:16px">Convolution Neural Network</li>
							<li style="font-size:16px">Computer Vision</li>
							<li style="font-size:16px">Text-to-Speech</li>


						</ul>
					
					<li style="font-size:16px"><b><a href="https://portal.vik.bme.hu/kepzes/targyak/VITMAB03/en/" target="_blank">Info-communications</a></b> (theoretical lecture)
						<ul>
							<li style="font-size:16px">Sound and Hearing <a href="pdf/lecture/Infocomm_09_sound_hearing.pdf" target="_blank"> [slides]</a></li>
							<li style="font-size:16px">Image and Vision <a href="pdf/lecture/Infocomm_10_light_vision.pdf" target="_blank"> [slides]</a></li>
							<li style="font-size:16px">Speech Processing <a href="pdf/lecture/Infocomm_11_speech_processing.pdf" target="_blank"> [slides]</a></li>
							<li style="font-size:16px">Radio communication <a href="pdf/lecture/Infocomm_12_radio_communication.pdf" target="_blank"> [slides]</a></li>
							<li style="font-size:16px">Video broadcasting <a href="pdf/lecture/Infocomm_13_video_broadcasting.pdf" target="_blank"> [slides]</a></li>

		
						</ul>
					


					<li style="font-size:16px"><b><a href="https://portal.vik.bme.hu/kepzes/targyak/VITMMA11/en/" target="_blank">Human-Computer Interaction</a></b> (practical lecture)
						<ul>
							<li style="font-size:16px">User interface </li>
							<li style="font-size:16px">Dialogue systems </li>
							<li style="font-size:16px">Case studies </li>

		
						</ul>
					

					<li style="font-size:16px"><b><a href="http://smartlab.tmit.bme.hu/csapo/AR/" target="_blank">Smart City Laboratory</a></b> (lab)
						<ul>
							<li style="font-size:16px">Augmented reality </li>
							<li style="font-size:16px">Virtual reality </li>
							<li style="font-size:16px">AR frameworks </li>

		
						</ul>





		


					</ul>
				</td>
			</tr>
		</tbody>
		
		</div>
		
		<br>



 
		<!-- <hr> -->
        <!-- Miscellaneous -->		
		
<!--         <h2> Miscellaneous </h2>

		<p>
		TODO
		</p>
		<br> -->



		<br>
		
		
		<hr>

        <!-- Professional Activity -->		
		
        <h2> Professional Activity </h2>
		
		
		<tbody>
			<tr>
			    <td>
					<ul>
				
						<li style="font-size:16px"><b>MTA</b>: 2023 - present
						<ul>
							<li style="font-size:16px">Member of the <a href="https://mta.hu/english" target="_blank">Hungarian Academy of Sciences</a></li>
						</ul>					
						
					
						<li style="font-size:16px"><b>IEEE</b>: 2017 - present
						<ul>
							<li style="font-size:16px">Member of the Institution of Electrical and Electronic Engineering, <a href="https://signalprocessingsociety.org/" target="_blank">Signal Processing Society</a></li>
						</ul>
						
						
						<li style="font-size:16px"><b>ISCA</b>: 2017 - present
						<ul>
							<li style="font-size:16px">Member of the International <a href="https://www.isca-speech.org/" target="_blank">Speech Communication</a> Association</a></li>
						</ul>
									
						
						<li style="font-size:16px"><b>IEICE</b>: 2019 â€“ 2021
						<ul>
							<li style="font-size:16px">Member of the Institute of <a href="https://www.ieice.org/" target="_blank">Electronics, Information and Communication Engineers</a>, Japan</li>
						</ul>
												
											
						
						<li style="font-size:16px"><b>IET</b>: 2012 â€“ 2016
						<ul>
							<li style="font-size:16px">Member of the Institution of <a href="https://www.theiet.org/" target="_blank">Engineering and Technology</a>, England</li>
						</ul>
												
						
					</ul>
				</td>
			</tr>
		</tbody>		
		
		
		<br>
		<br>




		<hr>
		
        <!-- Honors/Awards -->		
		
        <h2> Honors/Awards </h2>
		

		<p>
		<ul>
			<li style="font-size:16px"><b>2020: </b>PhD dissertation defense awarded 100% (Honours & Summa cum laude)</li>
			<li style="font-size:16px"><b>2016: </b>PhD scholarship, Budapest University of Technology and Economics, Hungary</li>
			<li style="font-size:16px"><b>2014: </b>1st prize, Rumaila golden winner, for Respect â€“ Determination - Personal Ownership - One team, Rumaila operating organization, Iraq</li>
			<li style="font-size:16px"><b>2013: </b>1st prize, MSc Top Student Certificate â€“ MSc Communication Systems Engineering, University of Portsmouth, UK</li>
			<li style="font-size:16px"><b>2011: </b>MSc scholarship, University of Portsmouth, UK</li>
			<li style="font-size:16px"><b>2007: </b>Excellence in research â€“ BSc dissertation, University of Basra, Iraq</li>
			
		<br>
		</ul>
		</p>
		<br>







		<hr>
        <!-- Reviewer -->		
        <h2> Reviewer & Programme Committee</h2>
		<!-- <p style="font-size:14px"><a href="https://publons.com/researcher/1712405/mohammed-salah-al-radhi/">Publons:</a> WoS ResearcherID C-9727-2018</li> -->
		<tbody>
			<tr>
			    <td>
					<ul>
						<li style="font-size:16px"><b>Journals</b>
						<ul>
							<li style="font-size:16px"><a href="https://www.journals.elsevier.com/computer-speech-and-language" target="_blank">Computer Speech and Language</a></li>
							<li style="font-size:16px"><a href="https://www.journals.elsevier.com/speech-communication" target="_blank">Speech Communication</a></li>
							<li style="font-size:16px"><a href="https://www.sciencedirect.com/journal/signal-processing" target="_blank">Signal Processing</a></li>
							<li style="font-size:16px"><a href="https://www.sciencedirect.com/journal/digital-signal-processing" target="_blank">Digital Signal Processing</a></li>
							<li style="font-size:16px"><a href="https://www.springer.com/journal/10462/" target="_blank">Artificial Intelligence Review</a></li>
							<!-- <li style="font-size:16px"><a href="https://www.springer.com/journal/11042" target="_blank">Multimedia Tools and Applications</a></li> -->
							<li style="font-size:16px"><a href="https://ieeeaccess.ieee.org/" target="_blank">IEEE Access</a></li>
							<li style="font-size:16px"><a href="https://www.infocommunications.hu/" target="_blank">HTE Infocommunication</a></li>
							<li style="font-size:14px">more ...</li>
							<!-- <li style="font-size:16px"><a href="https://www.sciencedirect.com/journal/heliyon" target="_blank">Heliyon</a></li> -->
							<!-- <li style="font-size:16px"><a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=19" target="_blank">IEEE Transactions on Instrumentation and Measurement</a></li> -->
							<!-- <li style="font-size:16px"><a href="https://www.worldscientific.com/worldscinet/fnl" target="_blank">Fluctuation and Noise Letters</a></li> -->
							<!-- <li style="font-size:16px">Indonesian Journal of Electrical Engineering and Computer Science (<a href="http://ijeecs.iaescore.com/index.php/IJEECS" target="_blank">IJEECS</a>)</li> -->
							<!-- <li style="font-size:16px"><a href="https://www.mdpi.com/about/journals" target="_blank">MDPI journals</a> (Applied Science, Acoustic, Electronics, Sensors, Mathematics)</li> -->
							
						</ul>
						
						<li style="font-size:16px"><b>Conferences</b>
						<ul>
							<li style="font-size:16px">ISCA<a href="https://www.isca-speech.org/iscaweb/index.php/conferences" target="_blank"> Interspeech</a></li>
							<li style="font-size:16px">ISCA Speech Synthesis Workshop (<a href="https://www.synsig.org/index.php/Speech_Synthesis_Workshop_(SSW)" target="_blank">SSW</a>)</li>
							<li style="font-size:16px">IEEE International Conference on Acoustics, Speech, and Signal Processing (<a href="https://dblp.org/db/conf/icassp/index.html" target="_blank">ICASSP</a>)</li>
							<li style="font-size:16px">IEEE Spoken Language Technology Workshop (<a href="https://dblp.org/db/conf/slt/index.html" target="_blank">SLT</a>)</li>
							<li style="font-size:16px">IEEE Workshop on Automatic Speech Recognition and Understanding (<a href="https://dblp.org/db/conf/asru/index.html" target="_blank">ASRU</a>)</li>
							<li style="font-size:14px">more ...</li>
							<!-- <li style="font-size:16px">International Joint Conference on Neural Networks<a href="https://ieeexplore.ieee.org/xpl/conhome/1000500/all-proceedings" target="_blank"> (IJCNN)</a></li> -->
							<!-- <li style="font-size:16px">International Conference on Speech Technology and Human-Computer Dialogue (<a href="https://sped.pub.ro/" target="_blank">SPeD</a>)</li> -->
							<!-- <li style="font-size:16px">International Conference on Arabic Natural Language Processing (<a href="https://arabicnlp2023.sigarab.org/" target="_blank">ArabicNLP</a>)</li> -->
							<!-- <li style="font-size:16px">The World Multi-Conference on Systemics, Cybernetics and Informatics (<a href="https://en.wikipedia.org/wiki/World_Multiconference_on_Systemics,_Cybernetics_and_Informatics" target="_blank">WMSCI</a>)</li> -->
							<!-- <li style="font-size:16px">VC challenge</li> -->
						</ul>
											
						<li style="font-size:16px"><b>Editorial Board</b>
						<ul>
							<li style="font-size:16px">Leading special issue editors for the journal of <a href="https://www.mdpi.com/journal/electronics/special_issues/847MLDA3C8" target="_blank">Electronics</a></li>
						</ul>
						
						<li <p style="font-size:16px">For a full list of verified reviews, please refer to <a href="https://www.webofscience.com/wos/author/record/676932" target="_blank">Web of Science ResearcherID: C-9727-2018</a></li>
					</u>
				</td>
			</tr>
		</tbody>
        <br>
        <br>




		<hr>
		
		<div id="Full Publications">
		
        <!-- Publications -->		
		
        <h2> Full Publications </h2>
		<tbody>
			<tr>
			    <td>
				
					<ul>
						<li style="font-size:16px"><b>2024</b></li>
						
						 <style>
						  ol {
							font-weight:bolder;
						  }

						  ol li span {
							font-weight: normal;
						  }
						</style>
		
		
						<ol>
							<li style="font-size:14px"><span>Shaimaa Alwaisi, <u>Mohammed Salah Al-Radhi</u>, GÃ©za NÃ©meth, <b> ChildTinyTalks (CTT): A Benchmark Dataset and Baseline for Expressive Child Speech Synthesis</b>, <i>26th International Conference on Speech and Computer (SPECOM). Lecture Notes in Computer Science</i>, Belgrade, Serbia, 2024, [ACCEPTED].							
							
							<li style="font-size:14px"><span>Shaimaa Alwaisi, <u>Mohammed Salah Al-Radhi</u>, GÃ©za NÃ©meth, <b> Multi-Speaker Child Speech Synthesis in Low-Resource Hungarian Language</b>, <i>2nd Workshop on Intelligent Infocommunication Networks, Systems and Services (WINS)</i>, Budapest, Hungary, 2024. <a href="https://doi.org/10.3311/WINS2024-004" target="_blank" style="color:blue"><p style="color:blue">[paper] &nbsp;&nbsp;&nbsp;<a href="pdf/students/shaimaa/Wins2_shaima.pdf" target="_blank" style="color:blue">[slides]</a></a></p></span></li>								
							
							<li style="font-size:14px"><span>Shukhrat Kulboboev, <u>Mohammed Salah Al-Radhi</u>, <b> Improving Speech Naturalness and Nuance using HiFiGAN-Hubert-Soft Vocoder: A Case Study of the Voicebox TTS Model</b>, <i>2nd Workshop on Intelligent Infocommunication Networks, Systems and Services (WINS)</i>, Budapest, Hungary, 2024. <a href="https://doi.org/10.3311/WINS2024-005" target="_blank" style="color:blue"><p style="color:blue">[paper] &nbsp;&nbsp;&nbsp;<a href="pdf/students/shukhrut/Kulboboev_WINS2_is2024_v2.pdf" target="_blank" style="color:blue">[slides]</a></a></p></span></li>	
							

							
						</ol>
					</ul>
				
				
				
				
				
				
					<ul>
						<li style="font-size:16px"><b>2023</b></li>
						
						 <style>
						  ol {
							font-weight:bolder;
						  }

						  ol li span {
							font-weight: normal;
						  }
						</style>
		
		
						<ol>
							<li style="font-size:14px"><span><u>Mohammed Salah Al-Radhi</u>, TamÃ¡s GÃ¡bor CsapÃ³, GÃ©za NÃ©meth, <b>Non-Parallel Voice Conversion with Emphasis on Expressive Voice: A Style-Based Approach</b>, <i>Socially responsibleâ€“Applied Linguistics Conference</i>, p. 19, Budapest, Hungary, 2023. <a href="http://resling.elte.hu/wp-content/uploads/2023/11/ResLing_Abstract_booklet_2023.pdf" target="_blank" style="color:blue"><p style="color:blue">[proceedings] &nbsp;&nbsp;&nbsp;<a href="pdf/malradhi_Resling_2013_certificate.pdf" target="_blank" style="color:blue">[certificate]</a></a></p></span></li>	
							<li style="font-size:14px"><span>Peter Mayer, Katharina Werner, <u>Mohammed Salah Al-Radhi</u>, TamÃ¡s GÃ¡bor CsapÃ³, BÃ¡lint Czeba, GÃ©za NÃ©meth, Ana PatrÃ­cia Rocha, IlÃ­dio C. Oliveira, Samuel Silva, Melinda Szeker, AntÃ³nio Teixeira, Paul Panek, <b>Concept and Pictogram-Based User-Interface Design of a Helper Tool for People with Aphasia</b>, <i>17th Annual Conference on Health Informatics meets Digital Health (dHealth)</i>, vol 301, pp. 77-82, Vienna, Austria, 2023. <a href="http://dx.doi.org/10.3233/SHTI230016" target="_blank" style="color:blue"><p style="color:blue">[paper] &nbsp;&nbsp;&nbsp;<a href="http://www.aal-europe.eu/projects/aph-alarm/" target="_blank" style="color:blue">[project]</a></a></p></li></span>
							<li style="font-size:14px"><span>Shaimaa Alwaisi, <u>Mohammed Salah Al-Radhi</u>, GÃ©za NÃ©meth, <b>Universal Approach to Multilingual Multispeaker Child Speech Synthesis</b>, <i>12th ISCA Speech Synthesis Workshop (SSW)</i>, pp. 236-237, Grenoble, France, 2023.<a href="https://www.isca-speech.org/archive/ssw_2023/alwaisi23_ssw.html" target="_blank" style="color:blue"><p style="color:blue">[paper] &nbsp;&nbsp;&nbsp;<a href="pdf/students/shaimaa/Poster_SSW12.pdf" target="_blank" style="color:blue">[poster]</a></a></p></li></span>
							<li style="font-size:14px"><span><u>Mohammed Salah Al-Radhi</u>, TamÃ¡s GÃ¡bor CsapÃ³, GÃ©za NÃ©meth, <b>Nonparallel Expressive TTS for Unseen Target Speaker using Style-Controlled Adaptive Layer and Optimized Pitch Embedding</b>, <i>12th International Conference on Speech Technology and Human-Computer Dialogue (SpeD)</i>, pp. 176-181, Bucharest, Romania, 2023.<a href="https://doi.org/10.1109/SpeD59241.2023.10314913" target="_blank" style="color:blue"><p style="color:blue">[paper] &nbsp;&nbsp;&nbsp;<a href="pdf/malradhi_SpeD_Style_v1_2023.pdf" target="_blank" style="color:blue">[slides] &nbsp;&nbsp;&nbsp;<a href="https://malradhi.github.io/expttsyle/" target="_blank" style="color:blue">[demo]</a></a></a></p></li></span>
							<li style="font-size:14px"><span>Ali Raheem Mandeel, <u>Mohammed Salah Al-Radhi</u>, TamÃ¡s GÃ¡bor CsapÃ³, <b>Modeling Irregular Voice in End-to-End Speech Synthesis via Speaker Adaptation</b>, <i>12th International Conference on Speech Technology and Human-Computer Dialogue (SpeD)</i>, pp. 170-175, Bucharest, Romania, 2023.<a href="https://doi.org/10.1109/SpeD59241.2023.10314920" target="_blank" style="color:blue"><p style="color:blue">[paper] &nbsp;&nbsp;&nbsp;<a href="https://aliraheem.github.io/Creaky/" target="_blank" style="color:blue">[demo]</a></a></p></li></span>	
							<li style="font-size:14px"><span>Shaimaa Alwaisi, <u>Mohammed Salah Al-Radhi</u>, GÃ©za NÃ©meth, <b>Automated Child Voice Generation: Methodology and Implementation</b>, <i>12th International Conference on Speech Technology and Human-Computer Dialogue (SpeD)</i>, pp. 48-53, Bucharest, Romania, 2023.<a href="https://doi.org/10.1109/SpeD59241.2023.10314889" target="_blank" style="color:blue"><p style="color:blue">[paper] &nbsp;&nbsp;&nbsp;<a href="https://shaimaalwaisi.github.io/Child_SpeechSynthesis/" target="_blank" style="color:blue">[demo]</a></a></p></li></span>
							<li style="font-size:14px"><span>Ali Raheem Mandeel, <u>Mohammed Salah Al-Radhi</u>, TamÃ¡s GÃ¡bor CsapÃ³, <b>Enhancing End-to-End Speech Synthesis by Modeling Interrogative Sentences with Speaker Adaptation</b>, <i>12th International Conference on Speech Technology and Human-Computer Dialogue (SpeD)</i>, pp. 158-163, Bucharest, Romania, 2023.<a href="https://doi.org/10.1109/SpeD59241.2023.10314910" target="_blank" style="color:blue"><p style="color:blue">[paper] &nbsp;&nbsp;&nbsp;<a href="https://aliraheem.github.io/interrogative/" target="_blank" style="color:blue">[demo]</a></a></p></li></span>	
							<li style="font-size:14px"><span><u>Mohammed Salah Al-Radhi</u>, Omnia Ibrahim, Ali Raheem Mandeel, TamÃ¡s GÃ¡bor CsapÃ³, GÃ©za NÃ©meth, <b>Advancing Limited Data Text-to-Speech Synthesis: Non-Autoregressive Transformer for High-Quality Parallel Synthesis</b>, <i>12th International Conference on Speech Technology and Human-Computer Dialogue (SpeD)</i>, pp. 152-157, Bucharest, Romania, 2023.<a href="https://doi.org/10.1109/SpeD59241.2023.10314948" target="_blank" style="color:blue"><p style="color:blue">[paper] &nbsp;&nbsp;&nbsp;<a href="pdf/malradhi_SpeD_arabicTTS_v2_2023.pdf" target="_blank" style="color:blue">[slides] &nbsp;&nbsp;&nbsp;<a href="https://malradhi.github.io/fast_arabic_tts/" target="_blank" style="color:blue">[demo]</a></a></a></p></li></span>
							<li style="font-size:14px"><span>Layan Swalha, <u>Mohammed Salah Al-Radhi</u>, <b>Improving Naturalness of Neural-based TTS System Trained with Limited Data</b>, <i>1st Workshop on Intelligent Infocommunication Networks, Systems and Services (WINS)</i>, pp. 71-75, Budapest, Hungary, 2023.<a href="http://dx.doi.org/10.3311/WINS2023-013" target="_blank" style="color:blue"><p style="color:blue">[paper] &nbsp;&nbsp;&nbsp;<a href="pdf/students/layan/poster_wins_2023.pdf" target="_blank" style="color:blue">[poster]</a></a></p></li></span>
							<li style="font-size:14px"><span>Ali Raheem Mandeel, Ammar Abdullah Aggar, <u>Mohammed Salah Al-Radhi</u>, TamÃ¡s GÃ¡bor CsapÃ³, <b>Implementing a Text-to-Speech synthesis model on a Raspberry Pi for Industrial Applications</b>, <i>1st Workshop on Intelligent Infocommunication Networks, Systems and Services (WINS)</i>, pp. 77-81, Budapest, Hungary, 2023.<a href="https://doi.org/10.3311/WINS2023-014" target="_blank" style="color:blue"><p style="color:blue">[paper] &nbsp;&nbsp;&nbsp;<a href="pdf/students/ali/poster_wins_2023.pdf" target="_blank" style="color:blue">[poster]</a></a></p></li></span>								
							<li style="font-size:14px"><span>Ali Raheem Mandeel, <u>Mohammed Salah Al-Radhi</u>, TamÃ¡s GÃ¡bor CsapÃ³, <b>Investigations on speaker adaptation using a continuous vocoder within recurrent neural network based textto-speech synthesis</b>, <i>Multimedia Tools and Applications</i>, 82, pp. 15635â€“15649, 2023.<a href="https://doi.org/10.1007/s11042-022-14005-5" target="_blank" style="color:blue"><p style="color:blue">[paper]</a></p></li></span>							
							<li style="font-size:14px"><span>Ali Raheem Mandeel, Ammar Abdullah Aggar, <u>Mohammed Salah Al-Radhi</u>, TamÃ¡s GÃ¡bor CsapÃ³, <b>A Smart Control System for the Oil Industry Using Text-to-Speech Synthesis Based on IIoT</b>, <i>Electronics</i>, 12(16):3380, 2023.<a href="https://doi.org/10.3390/electronics12163380" target="_blank" style="color:blue"><p style="color:blue">[paper]</a></p></li></span>							
							<li style="font-size:14px"><span><u>Mohammed Salah Al-Radhi</u>, TamÃ¡s GÃ¡bor CsapÃ³, GÃ©za NÃ©meth, <b>Improving the expressiveness of TTS synthesis with non-autoregressive neural vocoding</b>, <i>BeszÃ©dkutatÃ¡sâ€“Speech Research</i>, pp. 94-96, Budapest, Hungary, 2023.<a href="https://phon.nytud.hu/mady/transfer/beszkut_speechresearch_2023_proceedings.pdf#page=94" target="_blank" style="color:blue"><p style="color:blue">[proceedings] &nbsp;&nbsp;&nbsp;<a href="pdf/434--SR2023_malradhi_v1.pdf" target="_blank" style="color:blue">[poster]</a></a></p></li></span>							
							<li style="font-size:14px"><span>Ali Raheem Mandeel, <u>Mohammed Salah Al-Radhi</u>, TamÃ¡s GÃ¡bor CsapÃ³, <b>Creaky Voice via Speaker Adaptation within End-to-End Text to Speech Synthesis</b>, <i>BeszÃ©dkutatÃ¡sâ€“Speech Research</i>, pp. 78-80, Budapest, Hungary, 2023.<a href="https://phon.nytud.hu/mady/transfer/beszkut_speechresearch_2023_proceedings.pdf#page=78" target="_blank" style="color:blue"><p style="color:blue">[proceedings] &nbsp;&nbsp;&nbsp;<a href="pdf/students/ali/presentaion-SR2023.pdf" target="_blank" style="color:blue">[slides]</a></a></p></li></span>
							<li style="font-size:14px"><span>Layan Sawalha, <u>Mohammed Salah Al-Radhi</u>, <b>Few-Shot Multi-Language Text-to-Speech Synthesis with State-of-the-Art Neural Networks</b>, <i>BeszÃ©dkutatÃ¡sâ€“Speech Research</i>, pp. 97-99, Budapest, Hungary, 2023.<a href="https://phon.nytud.hu/mady/transfer/beszkut_speechresearch_2023_proceedings.pdf#page=97" target="_blank" style="color:blue"><p style="color:blue">[proceedings]</a></p></li></span>
						</ol>
					</ul>



					<ul>
						<li style="font-size:16px"><b>2022</b></li>
						
						 <style>
						  ol {
							font-weight:bolder;
						  }

						  ol li span {
							font-weight: normal;
						  }
						</style>
		
		
						<ol>
							<li style="font-size:14px"><span><u>Mohammed Salah Al-Radhi</u>, TamÃ¡s GÃ¡bor CsapÃ³, Csaba ZainkÃ³, GÃ©za NÃ©meth, <b> Towards Parametric Speech Synthesis Using Gaussian-Markov Model of Spectral Envelope and Wavelet-Based Decomposition of F0</b>, <i>30th European Signal Processing International Conference (EUSIPCO)</i>, Belgrade, Serbia, pp. 1150â€“1154, 2022.<a href="https://doi.org/10.23919/EUSIPCO55093.2022.9909745" target="_blank" style="color:blue"><p style="color:blue">[paper] &nbsp;&nbsp;&nbsp;<a href="pdf/1442_Al-Radhi_EUSIPCO2022.pdf" target="_blank" style="color:blue">[slides] &nbsp;&nbsp;&nbsp;<a href="http://smartlab.tmit.bme.hu/eusipco2022" target="_blank" style="color:blue">[demo]</a></a></a></p></li></span></li></span>
							<li style="font-size:14px"><span>Ali Raheem Mandeel, <u>Mohammed Salah Al-Radhi</u>, TamÃ¡s GÃ¡bor CsapÃ³, <b>Speaker Adaptation Experiments with Limited Data for End-to-End Text-To-Speech Synthesis using Tacotron2</b>, <i>Infocommunications Journal</i>, XIV, 3, pp. 55â€“62, 2022.<a href="https://doi.org/10.36244/ICJ.2022.3.7" target="_blank" style="color:blue"><p style="color:blue">[paper] &nbsp;&nbsp;&nbsp;<a href="https://aliraheem.github.io/infocommunications_journal_2022/" target="_blank" style="color:blue">[demo]</a></a></p></li></span></li></span>
							<li style="font-size:14px"><span>Ismaeil R. Alnaab, Harwan M. Taha, Zainab A. Abdulwahab, <u>Mohammed Salah Al-Radhi</u>, <b>Performance comparison between fixed tilt angle and solar tracking systems at Basra governorate: A case study</b>, <i>Indonesian Journal of Electrical Engineering and Computer Science</i>, 26(1):184â€“193, 2022.<a href="http://doi.org/10.11591/ijeecs.v26.i1.pp184-193" target="_blank" style="color:blue"><p style="color:blue">[paper]</p></a></li></span>	
							<li style="font-size:14px"><span>Safa Jameel Al-Kamil, <u>Mohammed Salah Al-Radhi</u>, <b>Deep Learning for Self-Driving Vehicles</b>, <i>2nd International Multi-Disciplinary Conference Theme: Integrated Sciences and Technologies (IMDC-IST)</i>, Sakarya, Turkey, 2022.<a href="http://dx.doi.org/10.4108/eai.7-9-2021.2314949" target="_blank" style="color:blue"><p style="color:blue">[paper]</p></a></li></span>	
							

							
						</ol>
					</ul>





					<ul>
						<li style="font-size:16px"><b>2021</b></li>
						
						 <style>
						  ol {
							font-weight:bolder;
						  }

						  ol li span {
							font-weight: normal;
						  }
						</style>
		
		
						<ol>
							<li style="font-size:14px"><span><u>Mohammed Salah Al-Radhi</u>, TamÃ¡s GÃ¡bor CsapÃ³, Csaba ZainkÃ³, GÃ©za NÃ©meth, <b>Continuous Wavelet Vocoder-Based Decomposition of Parametric Speech Waveform Synthesis</b>, <i>in Proceedings of Interspeech Conference</i>, Brno, Czechia, pp. 2212-2216, 2021.<a href="https://doi.org/10.21437/Interspeech.2021-1600" target="_blank" style="color:blue"><p style="color:blue">[paper] &nbsp;&nbsp;&nbsp;<a href="pdf/malradhi_Interspeech_cwt_2021.pdf" target="_blank" style="color:blue">[slides] &nbsp;&nbsp;&nbsp;<a href="https://malradhi.github.io/cwt_vocoder/" target="_blank" style="color:blue">[demo]</a></a></a></p></li></span></li></span>
							<li style="font-size:14px"><span>Pengyu Dai, <u>Mohammed Salah Al-Radhi</u>, TamÃ¡s GÃ¡bor CsapÃ³, <b>Effects of F0 Estimation Algorithms on Ultrasound-Based Silent Speech Interfaces</b>, <i>11th International Conference on Speech Technology and Human-Computer Dialogue (SpeD)</i>, Bucharest, Romania, pp. 47-51, 2021.<a href="pdf/students/pengyu/Dai-et-al-sped2021-paper.pdf" target="_blank" style="color:blue"><p style="color:blue">[paper] &nbsp;&nbsp;&nbsp;<a href="pdf/students/pengyu/PengyuDai_SR.pdf" target="_blank" style="color:blue">[slides] </a></a></p></span></li>							
							<li style="font-size:14px"><span><u>Mohammed Salah Al-Radhi</u>, TamÃ¡s GÃ¡bor CsapÃ³, GÃ©za NÃ©meth, <b>Noise and acoustic modeling with waveform generator in text-to-speech and neutral speech conversion</b>, <i>Multimedia Tools and Applications</i>, 80, 1969â€“1994, 2021.<a href="https://doi.org/10.1007/s11042-020-09783-9" target="_blank" style="color:blue"><p style="color:blue">[paper]</p></a></span></li>							
							<li style="font-size:14px"><span>Ali Raheem Mandeel, <u>Mohammed Salah Al-Radhi</u>, TamÃ¡s GÃ¡bor CsapÃ³, <b>Speaker Adaptation with Continuous Vocoder-Based DNN-TTS</b>, <i>23th International Conference on Speech and Computer (SPECOM). Lecture Notes in Computer Science</i>, 12997, pp. 407â€“416, 2021.<a href="https://doi.org/10.1007/978-3-030-87802-3_37" target="_blank" style="color:blue"><p style="color:blue">[paper]</a></p></span></li>
							<li style="font-size:14px"><span><u>Mohammed Salah Al-Radhi</u>, TamÃ¡s GÃ¡bor CsapÃ³, GÃ©za NÃ©meth, <b>Effects of Sinusoidal Model on Non-Parallel Voice Conversion with Adversarial Learning</b>, <i>Applied Sciences</i>, 11, 7489, pp. 1â€“16, 2021.<a href="https://doi.org/10.3390/app11167489" target="_blank" style="color:blue"><p style="color:blue">[paper] &nbsp;&nbsp;&nbsp;<a href="https://malradhi.github.io/contSM-VC/" target="_blank" style="color:blue">[demo]</a></a></p></span></li>
							<li style="font-size:14px"><span><u>Mohammed Salah Al-Radhi</u>, TamÃ¡s GÃ¡bor CsapÃ³, GÃ©za NÃ©meth, <b> Advances in speech vocoding for text-to-speech with continuous parameters</b>, <i>2nd International Conference on Artificial Intelligence and Speech Technology (AIST)</i>, Delhi, India, 2021.<a href="http://dx.doi.org/10.1201/9781003150664-23" target="_blank" style="color:blue"><p style="color:blue">[chapter]</a></p></span></li>
							
						</ol>
					</ul>





					<ul>
						<li style="font-size:16px"><b>2020</b></li>
						
						 <style>
						  ol {
							font-weight:bolder;
						  }

						  ol li span {
							font-weight: normal;
						  }
						</style>
		
		
						<ol>						
							<li style="font-size:14px"><span><u>Mohammed Salah Al-Radhi</u>, <b>High-Quality Vocoding Design with Signal Processing for Speech Synthesis and Voice Conversion</b>, <i>PhD Dissertation</i>, Budapest University of Technology and Economics, Faculty of Electrical Engineering and Informatyics, 2020.<a href="http://hdl.handle.net/10890/13411" target="_blank" style="color:blue"><p style="color:blue">[thesis]</a></p></span></li>		
							<li style="font-size:14px"><span><u>Mohammed Salah Al-Radhi</u>,  Omnia Abdo, TamÃ¡s GÃ¡bor CsapÃ³, Sherif Abdou, GÃ©za NÃ©meth, Mervat Fashal, <b>A continuous vocoder for statistical parametric speech synthesis and its evaluation using an audio-visual phonetically annotated Arabic corpus</b>, <i>Computer Speech and Language</i>, Volume 60, pp. 1-15, 2020.<a href="https://doi.org/10.1016/j.csl.2019.101025" target="_blank" style="color:blue"><p style="color:blue">[paper]</p></a></span></li>									
							<li style="font-size:14px"><span><u>Mohammed Salah Al-Radhi</u>, TamÃ¡s GÃ¡bor CsapÃ³, GÃ©za NÃ©meth, <b>Continuous Noise Masking Based Vocoder for Statistical Parametric Speech Synthesis</b>, <i>IEICE Transactions on Information and Systems</i>, E103.D, Issue 5, pp. 1099â€“1107, 2020.<a href="https://doi.org/10.1587/transinf.2019EDP7167" target="_blank" style="color:blue"><p style="color:blue">[paper] &nbsp;&nbsp;&nbsp;<a href="http://smartlab.tmit.bme.hu/cNM2019" target="_blank" style="color:blue">[demo]</a></a></p></span></li>	
							<li style="font-size:14px"><span><u>Mohammed Salah Al-Radhi</u>, TamÃ¡s GÃ¡bor CsapÃ³, GÃ©za NÃ©meth, <b>conTTS: Text-toSpeech Application using a Continuous Vocoder</b>, <i>12th International Seminar on Speech Production (ISSP)</i>, pp. 170-173, New Haven CT, USA, 2020.<a href="https://issp2020.yale.edu/ProcISSP2020.pdf#page=184" target="_blank" style="color:blue"><p style="color:blue">[proceedings] &nbsp;&nbsp;&nbsp;<a href="https://malradhi.github.io/conTTS/" target="_blank" style="color:blue">[demo]</a></a></p></span></li>
							<li style="font-size:14px"><span><u>Mohammed Salah Al-Radhi</u>, TamÃ¡s GÃ¡bor CsapÃ³, GÃ©za NÃ©meth, <b> Non-Parallel Voice Conversion Incorporating Sinusoidal Model with Adversarial Learning</b>, <i>BeszÃ©dkutatÃ¡sâ€“Speech Research</i>, pp. 77-79, 2020.<a href="http://real.mtak.hu/118352/1/beszkut_speechresearch_2020_proceedings.pdf#page=77" target="_blank" style="color:blue"><p style="color:blue">[paper]</a></p></span></li>
							
						</ol>
					</ul>




					<ul>
						<li style="font-size:16px"><b>2019</b></li>
						 <style>
						  ol {
							font-weight:bolder;
						  }

						  ol li span {
							font-weight: normal;
						  }
						</style>
						<ol>								
							<li style="font-size:14px"><span><u>Mohammed Salah Al-Radhi</u>,  TamÃ¡s GÃ¡bor CsapÃ³, GÃ©za NÃ©meth, <b>Continuous vocoder applied in deep neural network based voice conversion</b>, <i>Multimedia Tools and Applications</i>, 78, pp. 33549â€“33572, 2019.<a href="https://doi.org/10.1007/s11042-019-08198-5" target="_blank" style="color:blue"><p style="color:blue">[paper] &nbsp;&nbsp;&nbsp;<a href="http://smartlab.tmit.bme.hu/vc2019" target="_blank" style="color:blue">[demo]</a></a></p></span></li>										
							<li style="font-size:14px"><span><u>Mohammed Salah Al-Radhi</u>, TamÃ¡s GÃ¡bor CsapÃ³, GÃ©za NÃ©meth, <b>Parallel Voice Conversion Based on a Continuous Sinusoidal Model</b>, <i>10th International Conference on Speech Technology and Human-Computer Dialogue (SpeD)</i>, Timisoara, Romania, pp. 1-6, 2019.<a href="https://doi.org/10.1109/SPED.2019.8906565" target="_blank" style="color:blue"><p style="color:blue">[paper] &nbsp;&nbsp;&nbsp;<a href="pdf/SpeD_is2019_NG_malradhi.pdf" target="_blank" style="color:blue">[slides] &nbsp;&nbsp;&nbsp;<a href="http://smartlab.tmit.bme.hu/sped2019_vc" target="_blank" style="color:blue">[demo]</a></a></a></p></span></li>							
							<li style="font-size:14px"><span>TamÃ¡s GÃ¡bor CsapÃ³, <u>Mohammed Salah Al-Radhi</u>, GÃ©za NÃ©meth, GÃ¡bor Gosztolya, TamÃ¡s GrÃ³sz, LÃ¡szlÃ³ TÃ³th, Alexandra MarkÃ³, <b> Ultrasound-Based Silent Speech Interface Built on a Continuous Vocoder</b>, <i>in Proceedings of Interspeech Conference</i>, Graz, Austria, pp. 894-898, 2019.<a href="http://dx.doi.org/10.21437/Interspeech.2019-2046" target="_blank" style="color:blue"><p style="color:blue">[paper] &nbsp;&nbsp;&nbsp;<a href="http://smartlab.tmit.bme.hu/interspeech2019_ssi_f0" target="_blank" style="color:blue">[demo]</a></a></p></span></li>
							<li style="font-size:14px"><span>Waleed I., Baha Sawadi, Safa Al-Kamil,<u>Mohammed Salah Al-Radhi</u>, Yasir Al-Yasir, Ameer Saleh, Raed Abd-Alhameed, <b>Prediction of Solar Irradiance Based on Artificial Neural Networks</b>, <i>Inventions</i>, 4(3), 45, pp. 1-10, 2019.<a href="https://doi.org/10.3390/inventions4030045" target="_blank" style="color:blue"><p style="color:blue">[paper]</a></p></span></li>
							<li style="font-size:14px"><span><u>Mohammed Salah Al-Radhi</u>,  TamÃ¡s GÃ¡bor CsapÃ³, GÃ©za NÃ©meth, <b>Adaptive Refinements of Pitch Tracking and HNR Estimation within a Vocoder for Statistical Parametric Speech Synthesis</b>, <i>Applied Sciences</i>, 9 (12), 2460, pp. 1â€“23, 2019.<a href="https://doi.org/10.3390/app9122460" target="_blank" style="color:blue"><p style="color:blue">[paper] &nbsp;&nbsp;&nbsp;<a href="http://smartlab.tmit.bme.hu/adContF0_2019" target="_blank" style="color:blue">[demo]</a></a></p></span></li>										
							<li style="font-size:14px"><span><u>Mohammed Salah Al-Radhi</u>,  TamÃ¡s GÃ¡bor CsapÃ³, GÃ©za NÃ©meth, <b>RNN-based speech synthesis using a continuous sinusoidal model</b>, <i> International Joint Conference on Neural Networks (IJCNN)</i>, Budapest, Hungary, pp. 1-8, 2019.<a href="https://doi.org/10.1109/IJCNN.2019.8852253" target="_blank" style="color:blue"><p style="color:blue">[paper] &nbsp;&nbsp;&nbsp;<a href="pdf/malradhi_IJCNN_is2019_v3.pdf" target="_blank" style="color:blue">[slides] &nbsp;&nbsp;&nbsp;<a href="http://smartlab.tmit.bme.hu/ijcnn2019_vocoder" target="_blank" style="color:blue">[demo]</a></a></a></p></span></li>										
							<li style="font-size:14px"><span><u>Mohammed Salah Al-Radhi</u>,  TamÃ¡s GÃ¡bor CsapÃ³, GÃ©za NÃ©meth, <b>High quality continuous vocoder in deep recurrent neural network based speech synthesis</b>, <i>in Eastern European Machine Learning, Google DeepMind</i>, Bucharest, Romania, 2019.<a href="https://malradhi.github.io/pdf/is2019_EEML_poster.pdf" target="_blank" style="color:blue"><p style="color:blue">[poster]</a></p></span></li>										
						</ol>
					</ul>
							
							
							
							
							
							
							
					<ul>
						<li style="font-size:16px"><b>2018</b></li>
						 <style>
						  ol {
							font-weight:bolder;
						  }

						  ol li span {
							font-weight: normal;
						  }
						</style>
						<ol>								
							<li style="font-size:14px"><span><u>Mohammed Salah Al-Radhi</u>, TamÃ¡s GÃ¡bor CsapÃ³, GÃ©za NÃ©meth, <b>A Continuous Vocoder using Sinusoidal Model for Statistical Parametric Speech Synthesis</b>, <i>20th International Conference on Speech and Computer (SPECOM), Lecture Notes in Computer Science</i>, Leipzig, Germany, pp. 11â€“20, 2018.<a href="https://doi.org/10.1007/978-3-319-99579-3_2" target="_blank" style="color:blue"><p style="color:blue">[paper] &nbsp;&nbsp;&nbsp;<a href="pdf/malradhi_SPECOM_is2018_v2.pdf" target="_blank" style="color:blue">[slides] &nbsp;&nbsp;&nbsp;<a href="http://smartlab.tmit.bme.hu/specom2018" target="_blank" style="color:blue">[demo]</a></a></a></p></span></li>																	
							<li style="font-size:14px"><span><u>Mohammed Salah Al-Radhi</u>, TamÃ¡s GÃ¡bor CsapÃ³, GÃ©za NÃ©meth, <b>Improving continuous F0 estimator with adaptive time-warping for high-quality speech synthesis</b>, <i>in BeszÃ©dkutatÃ¡s (conference of the speech reseacrch)</i>, Budapest, Hungary, pp. 77-79, 2018.<a href="http://real.mtak.hu/118352/1/beszkut_speechresearch_2020_proceedings.pdf#page=77" target="_blank" style="color:blue"><p style="color:blue">[proceedings]</a></p></span></li>																		
						</ol>
					</ul>
						


						
						
							
							
							
							
							
							
							
					<ul>
						<li style="font-size:16px"><b>2017</b></li>
						 <style>
						  ol {
							font-weight:bolder;
						  }

						  ol li span {
							font-weight: normal;
						  }
						</style>
						<ol>								
							<li style="font-size:14px"><span><u>Mohammed Salah Al-Radhi</u>, TamÃ¡s GÃ¡bor CsapÃ³, GÃ©za NÃ©meth, <b>Time-Domain Envelope Modulating the Noise Component of Excitation in a Continuous Residual-Based Vocoder for Statistical Parametric Speech Synthesis</b>, <i> In proceedings of Interspeech</i>, Stockholm, Sweden,  pp. 434-438, 2017.<a href="http://dx.doi.org/10.21437/Interspeech.2017-678" target="_blank" style="color:blue"><p style="color:blue">[paper] &nbsp;&nbsp;&nbsp;<a href="pdf/is2017_envelope_Interspeech_poster_v4_malradhi.pdf" target="_blank" style="color:blue">[slides] &nbsp;&nbsp;&nbsp;<a href="http://smartlab.tmit.bme.hu/interspeech2017_vocoder_envelope" target="_blank" style="color:blue">[demo]</a></a></a></p></span></li>																	
							<li style="font-size:14px"><span><u>Mohammed Salah Al-Radhi</u>, TamÃ¡s GÃ¡bor CsapÃ³, GÃ©za NÃ©meth, <b>Continuous vocoder in feed-forward deep neural network based speech synthesis</b>, <i>International conference of digital speech and image processing</i>, Novi Sad, Serbia, pp. 1-4, 2017.<a href="http://smartlab.tmit.bme.hu/downloads/pdf/csapot/AlRadhi-et-al-dogs2017.pdf" target="_blank" style="color:blue"><p style="color:blue">[paper] &nbsp;&nbsp;&nbsp;<a href="pdf/malradhi_DOGS_2017_v2.pdf" target="_blank" style="color:blue">[slides] &nbsp;&nbsp;&nbsp;<a href="http://smartlab.tmit.bme.hu/dogs2017_vocoder_dnn" target="_blank" style="color:blue">[demo]</a></a></a></p></span></li>																		
							<li style="font-size:14px"><span><u>Mohammed Salah Al-Radhi</u>, TamÃ¡s GÃ¡bor CsapÃ³, GÃ©za NÃ©meth, <b>Effects of adding a Harmonic-to-Noise Ratio parameter to a continuous vocoder</b>, <i>in Proceedings of the 6th of the UK Speech</i>, Cambridge University, England, 2017.<a href="http://mi.eng.cam.ac.uk/UKSpeech2017/posters/m_al-radhi.pdf" target="_blank" style="color:blue"><p style="color:blue">[poster]</a></p></span></li>																		
							<li style="font-size:14px"><span><u>Mohammed Salah Al-Radhi</u>, TamÃ¡s GÃ¡bor CsapÃ³, GÃ©za NÃ©meth, <b>Deep Recurrent Neural Networks in Speech Synthesis Using a Continuous Vocoder</b>, <i>19th International Conference on Speech and Computer (SPECOM). Lecture Notes in Computer Science</i>, Hatfield, UK, pp. 282â€“291, 2017.<a href="https://doi.org/10.1007/978-3-319-66429-3_27" target="_blank" style="color:blue"><p style="color:blue">[paper] &nbsp;&nbsp;&nbsp;<a href="pdf/malradhi_SPECOM_poster_v2_CsTG.pdf" target="_blank" style="color:blue">[poster]</a></a></p></span></li>	
							<li style="font-size:14px"><span><u>Mohammed Salah Al-Radhi</u>, <b> High quality continuous residual-based vocoder for statistical parametric speech synthesis</b>, <i>3rd Doctoral Consortium, International Speech Communication Association (ISCA-SAC),  Interspeech, KTH Royal Institute of Technology</i>, Stockholm, Sweden, 2017.<a href="http://www.isca-students.org/sacweb/images/files/resources/3rdDC/3DC_paper_1.pdf" target="_blank" style="color:blue"><p style="color:blue">[paper]</a></p></span></li>	
						</ol>
					</ul>





					<ul>
						<li style="font-size:16px"><b>2012</b></li>
						 <style>
						  ol {
							font-weight:bolder;
						  }

						  ol li span {
							font-weight: normal;
						  }
						</style>
						<ol>								
							<li style="font-size:14px"><span><u>Mohammed Salah Al-Radhi</u>, <b>Design of Finite Impulse Response Digital Filters using Optimal Methods</b>, <i>MSc Dissertation</i>, Portsmouth University, School of Energy and Electronic Engineering, Portsmouth, England, 2012.<a href="http://dx.doi.org/10.13140/RG.2.2.23230.38726" target="_blank" style="color:blue"><p style="color:blue">[thesis]</a></p></span></li>	
							<li style="font-size:14px"><span><u>Mohammed Salah Al-Radhi</u>, <b>Performance of Convolutional coding with Hard decision Viterbi decoding on BPSK Systems over Noisy Channels</b>, <i>Student Symposium</i>, Portsmouth University, School of Engineering, Portsmouth, England, 2012.<a href="pdf/malradhi_BPSK_2013.pdf" target="_blank" style="color:blue"><p style="color:blue">[paper]</a></p></span></li>
						</ol>
					</ul>
						

				</td>
			</tr>
		</tbody>
		
		</div>












		<!-- <hr> -->
        <!-- Scientific and Societal Impact of Research -->		
		
<!--         <h2> Scientific and Societal Impact of Research </h2>

		<p>
		7 journals (6 published / 1 under revision) and 12 international conference (10 published / 2 under revision) papers. For a full list of publications please refer to <a href="https://scholar.google.com/citations?user=cUq-wkMAAAAJ&hl=en&oi=ao" onclick="_gaq.push(['_trackEvent', 'Click', 'Scholar Clicked']);" style="margin-right:14px;">
                <i class="ai ai-google-scholar big-icon" style="font-size:33px;"></i>
            </a> 
		</p> -->


        <br>
        <br>	
		
		
		<!-- <div class="container text-center"><a class="cc-facebook btn btn-link" target="_blank" href="https://www.facebook.com/ce.mohammedsalah"><i class="fa fa-facebook fa-2x " aria-hidden="true"></i></a><a class="cc-instagram btn btn-link" target="_blank" href="https://www.instagram.com/b/"><i class="fa fa-instagram fa-2x " aria-hidden="true"></i></a></div> -->
		
		
		
		
		<hr>
		<i>Last updated: Thursday, 18<sup style="font-size:12px;">th</sup> January 2024 (<a href="http://en.wikipedia.org/wiki/ISO_8601" target="_blank">ISO 8601</a>)</i>
		
		<br>
		
<!-- 		 <script type='text/javascript' src='https://www.freevisitorcounters.com/auth.php?id=5d640d536679c7cd357192945f94f8955cfa2b60'></script>
		 <script type="text/javascript" src="https://www.freevisitorcounters.com/en/home/counter/880718/t/2"></script> -->
		
		
		
		
		 <a href='http://www.freevisitorcounters.com'>All counters 100%</a> <script type='text/javascript' src='https://www.freevisitorcounters.com/auth.php?id=5d640d536679c7cd357192945f94f8955cfa2b60'></script>
		 <script type="text/javascript" src="https://www.freevisitorcounters.com/en/home/counter/880718/t/2"></script>
		
		
		
		
		<br>
		<br>
		
		
		<hr>
		
		<!-- <a target="_top" href="https://clustrmaps.com/site/1by5o" title="Visit tracker" id="clustrmaps-widget-v2" class="clustrmaps-map-control" style="width: 405px;"><img src="//www.clustrmaps.com/map_v2.png?d=kiTlmd79af0ncHhMRkt8tJBpDlRnkyb1s1bECxH96Qk&cl=ffffff" /><div class="jvectormap-container" style="background-color: transparent;"><svg width="405" height="199"></svg><div class="jvectormap-legend-cnt jvectormap-legend-cnt-h"></div><div class="jvectormap-legend-cnt jvectormap-legend-cnt-v"></div></div></div><div id="clstminf" style="display: table-cell;position: absolute;bottom: 3px;right: 5px;color: white;font-size: 12px;"></div></div><div class=""></div></a> -->
		
		<a href='https://clustrmaps.com/site/1by5o'  title='Visit tracker'><img src='//clustrmaps.com/map_v2.png?cl=ffffff&w=400&t=m&d=kiTlmd79af0ncHhMRkt8tJBpDlRnkyb1s1bECxH96Qk'/></a>
		<!-- <a target="_top" href="http://clustrmaps.com/site/1bi07?utm_source=widget&amp;utm_campaign=widget_ctr" id="clustrmaps-widget-v2" class="clustrmaps-map-control" style="width: 405px;"><div class="clustrmaps-map-container" style="background-color: rgb(45, 120, 173);"><div class="clstm clustrmaps-visitors" style="font-size: 14px; line-height: 16px; color: rgb(255, 255, 255);">339 Pageviews</div><div class="clstm clustrmaps-date" style="font-size: 14px; line-height: 16px; color: rgb(255, 255, 255);">Dec. 13th - Jan. 13th</div><div class="clustrmaps-map liveDotsReady" style="width: 405px; height: 198.529px; background-image: url(&quot;//clustrmaps.com/generated_content/backs/bg-w_405-cl_ffffff.png&quot;);"><div class="jvectormap-container" style="background-color: transparent;"><svg width="405" height="199"><defs></defs><g transform="scale(0.375) translate(90, 44.98017796126684)"></g><g></g><g style="visibility: visible;"><circle data-index="0" cx="298.397890925166" cy="89.68662197461676" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="4" class="jvectormap-marker jvectormap-element"></circle><circle data-index="1" cx="99.75165561287729" cy="86.48817920793373" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="3" class="jvectormap-marker jvectormap-element"></circle><circle data-index="2" cx="298.8111491937668" cy="102.46494796021055" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="3" class="jvectormap-marker jvectormap-element"></circle><circle data-index="3" cx="298.8267367585448" cy="102.33344534047788" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="4" cx="119.69913738001011" cy="84.67041916208933" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="5" cx="76.72459689118091" cy="75.28007202698764" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="6" cx="298.79546772799625" cy="102.4321043508426" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="7" cx="127.75480963745166" cy="96.713505414765" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="8" cx="300.8972536462178" cy="84.10037004331508" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="9" cx="298.74851723167717" cy="102.34982581177591" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="10" cx="305.6030079912904" cy="93.59187630807827" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="11" cx="305.72705120256546" cy="99.68753613450939" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="12" cx="298.7797862622257" cy="102.18537327529616" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="13" cx="303.1410178653085" cy="92.53700481434421" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="14" cx="289.128078832912" cy="122.48823143247165" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="15" cx="326.0834717926378" cy="156.3669542082344" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="16" cx="322.8354364572813" cy="88.71451705495502" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="17" cx="226.92064313092695" cy="65.10524268567809" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="18" cx="310.8429650834818" cy="86.68468786345072" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="19" cx="207.7527274046767" cy="78.61313538763265" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="20" cx="117.9747395512016" cy="89.01458095852729" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="21" cx="80.55632079677673" cy="90.45231734157576" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="22" cx="119.64598941817692" cy="84.73330808537033" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="23" cx="124.4909989353319" cy="82.04756110050086" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="24" cx="289.1141814860016" cy="88.31629193020522" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="25" cx="288.9858188290651" cy="122.43648318933012" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="26" cx="76.84234873594923" cy="75.06486086949366" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="27" cx="304.4402319994511" cy="94.36810786480407" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="28" cx="77.04789800883432" cy="86.69282427680241" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="29" cx="77.15015618981738" cy="86.94069466595224" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="30" cx="297.8204937214335" cy="96.53232287272343" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="31" cx="186.5595550692051" cy="89.92732249813612" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="32" cx="118.72566578932958" cy="80.47833745737833" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="33" cx="78.61951892262047" cy="86.21758871241632" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="34" cx="124.56527462050875" cy="81.69324543535582" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="35" cx="77.09137416842586" cy="87.03681554975103" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="36" cx="311.25584774811216" cy="88.03255973896546" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="37" cx="191.58870443292366" cy="70.53226510105168" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="38" cx="118.85975640681696" cy="85.0713472203991" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="39" cx="76.8154930520547" cy="86.42330058605893" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="40" cx="117.07676435860215" cy="79.93332010431394" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="41" cx="233.4061968904645" cy="83.8209846073252" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="42" cx="305.22768572371535" cy="101.22864180154818" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="43" cx="305.2014873467693" cy="109.90116092359051" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="44" cx="288.967695937486" cy="122.46841504119914" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="45" cx="310.53309180777563" cy="77.48236233848326" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="46" cx="185.99586741039775" cy="86.88805899301352" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="47" cx="192.65607701624248" cy="70.87255222286326" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="48" cx="199.76212853513354" cy="72.2496986383924" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="49" cx="112.53824768141834" cy="90.72391571623726" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="50" cx="118.87609517953601" cy="85.13777351870093" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="51" cx="122.11558552456246" cy="83.20352518817157" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="52" cx="76.93024006505863" cy="75.21108837085993" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="53" cx="239.10063478702506" cy="98.49121924721805" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="54" cx="218.814733842424" cy="82.88973851175646" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="55" cx="305.182613247249" cy="93.2418642018749" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="56" cx="297.95035879425217" cy="101.60850449782502" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="57" cx="310.6070857899746" cy="86.80809144444346" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="58" cx="196.24544245983898" cy="69.47136009863715" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="59" cx="102.74512535719155" cy="85.13656607119654" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="60" cx="109.3002597522741" cy="81.85391373760773" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="61" cx="191.55114403586833" cy="70.5040543129303" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="62" cx="220.02586884547196" cy="59.45920428442285" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="63" cx="215.07991576123084" cy="77.19332383420377" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="64" cx="304.9285171611699" cy="100.58954694313083" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="65" cx="298.91134155291184" cy="94.07281417291927" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="66" cx="298.38925203384326" cy="101.69354051970079" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="67" cx="333.48117979466326" cy="156.87771954148235" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="68" cx="191.4925498164621" cy="70.54474526308283" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="69" cx="195.69217781121452" cy="71.34825466973115" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="70" cx="114.22931065784032" cy="95.03209910713952" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="71" cx="107.02588380958343" cy="94.70798980776898" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="72" cx="99.8742903092628" cy="94.35914868621394" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="73" cx="116.72482343819405" cy="83.48506025013735" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="74" cx="79.36856714089566" cy="77.4486715850679" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="75" cx="122.51062700059153" cy="77.77497865080962" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="76" cx="322.7411598606725" cy="88.48781744302173" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="77" cx="239.84132581695542" cy="70.87255222286326" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="78" cx="291.00168533902274" cy="103.66167969830552" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="79" cx="304.5834310132244" cy="102.10487850771842" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="80" cx="305.6870493797016" cy="93.38024148597373" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="81" cx="291.6616215152843" cy="95.11894821023913" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="82" cx="321.1908544722153" cy="88.37738388039175" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="83" cx="326.5901615489137" cy="161.69638457311459" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="84" cx="200.23069448839829" cy="73.8964467633867" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="85" cx="114.3196434127583" cy="92.42300594123898" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="86" cx="122.10732223721028" cy="83.14622774142268" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="87" cx="298.7917116882908" cy="102.43585251830704" fill="#FF0000" stroke="#ffffff" fill-opacity="0.7" stroke-width="0.5" stroke-opacity="1" r="2" class="jvectormap-marker jvectormap-element"></circle><circle data-index="90662111" cx="233.4061968904645" cy="83.8209846073252" fill="#F8A400" stroke="#FFFFFF" fill-opacity="1" stroke-width="0.4" stroke-opacity="1" r="4" class="jvectormap-marker jvectormap-element"></circle></g><g></g></svg><div class="jvectormap-legend-cnt jvectormap-legend-cnt-h"></div><div class="jvectormap-legend-cnt jvectormap-legend-cnt-v"></div></div></div><div id="clstminf" style="display: table-cell;position: absolute;bottom: 3px;right: 5px;color: white;font-size: 12px;"></div></div><div class=""></div></a> -->
		
		<!-- <a target="_top" href="https://clustrmaps.com/site/1by5o?utm_source=widget&amp;utm_campaign=widget_ctr" id="clustrmaps-widget-v2" class="clustrmaps-map-control" style="width: 405px;"><div class="clustrmaps-map-container" style="background-color: rgb(45, 120, 173);"><div class="clstm clustrmaps-visitors" style="font-size: 14px; line-height: 16px; color: rgb(255, 255, 255);">339 Pageviews</div><div class="clstm clustrmaps-date" style="font-size: 14px; line-height: 16px; color: rgb(255, 255, 255);">Dec. 13th - Jan. 13th</div><div class="clustrmaps-map liveDotsReady" style="width: 405px; height: 198.529px; background-image: url(&quot;//clustrmaps.com/generated_content/backs/bg-w_405-cl_ffffff.png&quot;);"><div class="jvectormap-container" style="background-color: transparent;"><svg width="405" height="199"></svg><div class="jvectormap-legend-cnt jvectormap-legend-cnt-h"></div><div class="jvectormap-legend-cnt jvectormap-legend-cnt-v"></div></div></div><div id="clstminf" style="display: table-cell;position: absolute;bottom: 3px;right: 5px;color: white;font-size: 12px;"></div></div><div class=""></div></a> -->
		
		<!-- <a target="_top" href="https://clustrmaps.com/site/1by5o" id="clustrmaps-widget-v2" class="clustrmaps-map-control" style="width: 405px;"><div class="clustrmaps-map-container" style="background-color: rgb(45, 120, 173);"><div class="clstm clustrmaps-visitors" style="font-size: 14px; line-height: 16px; color: rgb(255, 255, 255);">339 Pageviews</div><div class="clstm clustrmaps-date" style="font-size: 14px; line-height: 16px; color: rgb(255, 255, 255);">Dec. 13th - Jan. 13th</div><div class="clustrmaps-map liveDotsReady" style="width: 405px; height: 198.529px; background-image: url(&quot;//clustrmaps.com/generated_content/backs/bg-w_405-cl_ffffff.png&quot;);"><div class="jvectormap-container" style="background-color: transparent;"><svg width="405" height="199"></svg><div class="jvectormap-legend-cnt jvectormap-legend-cnt-h"></div><div class="jvectormap-legend-cnt jvectormap-legend-cnt-v"></div></div></div><div id="clstminf" style="display: table-cell;position: absolute;bottom: 3px;right: 5px;color: white;font-size: 12px;"></div></div><div class=""></div></a> -->
		
		
		
		
		
		
		<!-- <a href="https://info.flagcounter.com/YgxE"><img src="https://s11.flagcounter.com/count2/YgxE/bg_FFFFFF/txt_000000/border_CCCCCC/columns_2/maxflags_10/viewers_0/labels_1/pageviews_1/flags_0/percent_0/" alt="Flag Counter" border="0"></a> -->
		

 <!--        <p>
        	My research focuses on bringing clarity to the central philosophical questions surrounding computation and learning.
       	</p>

        <p>
            I am currently interested in characterizing the nature of computational worlds that can contain sophisticated phenomena such as intelligent agents. Previously, my <a href="https://david-abel.github.io/thesis.pdf">dissertation</a> investigated how rational agents model the worlds they inhabit, focusing on the representational practices that underly effective learning and planning.
        </p>

        <p>
			I typically work with the reinforcement learning problem, drawing on tools and perspectives from computational learning theory, computational complexity, and analytic philosophy. I value research that concentrates on providing new understanding, and tend to get excited by simple but foundational questions.
        </p>
        	
        <p></p>


        FEATURED PUBLICATIONS
        <h3> Featured Research </h3>


        <table style="margin-top:-12px;">

            Work
            <tbody><tr style="border-bottom:1px solid #e5e5e5;">
                IMAGE
                <td>
                    <img class="workPicture" src="images/thesis_overview.jpg" alt="Thesis overview">
                </td>

                TITLE AND INFO
                <td>
                    <br>
                    <div id="indexWorkText">
                        Title + Link
                        <b><a href="https://david-abel.github.io/thesis.pdf" onclick="_gaq.push(['_trackEvent', 'Click', 'Thesis (b) Clicked']);">A Theory of Abstraction in Reinforcement Learning </a></b>
                        <br>
                        <i>Ph.D Thesis, 2020</i>
                    </div>
                    <br>
                    One sentence description
                    <div id="indexWorkText">
                        My dissertation, aimed at understanding abstraction and its role in effective reinforcement learning.
                    </div>
                    <br>

                    Collaborators
                    <div id="indexWorkText">
                        Advised by <a href="http://cs.brown.edu/~mlittman/">Michael L. Littman</a>.
                    </div>
                    <br>
                    <br>
                </td>
            </tr>

            Work
            <tr style="border-bottom:1px solid #e5e5e5;">
                IMAGE
                <td>
                    <img class="workPicture" src="images/vpsa1.jpg" alt="Value Preserving Abstractions">
                </td>

                TITLE AND INFO
                <td>
                    <br>
                    <div id="indexWorkText">
                        Title + Link
                        <b><a href="papers/aistats2020_vpsa-full.pdf" onclick="_gaq.push(['_trackEvent', 'Click', 'VPSA Paper Clicked']);">Value Preserving State-Action Abstractions </a></b>
                        <br>
                        <i>AISTATS 2020</i>
                    </div>
                    <br>
                    One sentence description
                    <div id="indexWorkText">
                        We prove which combinations of state abstractions and options are guaranteed to preserve representation of near-optimal policies in any finite Markov Decision Process.
                    </div>
                    <br>

                    Collaborators
                    <div id="indexWorkText">
                        Joint work with <a href="https://www.linkedin.com/in/umbanhowar">Nathan Umbanhowar</a>, <a href="shttps://kkhetarpal.github.io/">Khimya Khetarpal</a>, <a href="http://dilipa.github.io/">Dilip Arumugam</a>, <a href="https://www.cs.mcgill.ca/~dprecup/">Doina Precup</a>, and <a href="http://cs.brown.edu/~mlittman/">Michael L. Littman</a>.
                    </div>
                    <br>
                    <br>
                </td>
            </tr>

            Work
            <tr style="border-bottom:1px solid #e5e5e5;">
                IMAGE
                <td>
                    <img class="workPicture" src="images/lipschitz_rl-narrow.jpg" alt="Lipschitz Lifelong Reinforcement Learning">
                </td>

                TITLE AND INFO
                <td>
                    <br>
                    <div id="indexWorkText">
                        Title + Link
                        <b><a href="papers/aaai2021_lipschitz.pdf" onclick="_gaq.push(['_trackEvent', 'Click', 'Lipschitz Paper Clicked']);">Lipschitz Lifelong Reinforcement Learning</a></b>
                        <br>
                        <i>AAAI 2021</i>
                    </div>
                    <br>
                    One sentence description
                    <div id="indexWorkText">
                        We examine the Lipschitz continuity of value functions and MDPs, then exploit these properties to develop a PAC-MDP algorithm for lifelong RL called Lipschitz RMax.
                    </div>
                    <br>

                    Collaborators
                    <div id="indexWorkText">
                        Led by <a href="https://erwanlecarpentier.github.io/">Erwan Lecarpentier</a>, joint with <a href="http://cs.brown.edu/people/kasadiat/">Kavosh Asadi</a>, <a href="https://jinnaiyuu.github.io/">Yuu Jinnai</a>, <a href="https://people.isae-supaero.fr/emmanuel-rachelson?lang=en">Emmanuel Rachelson</a>, and <a href="http://cs.brown.edu/~mlittman/">Michael L. Littman</a>.
                    </div>
                    <br>
                    <br>
                </td>
            </tr>

            Work
            <tr style="border-bottom:1px solid #e5e5e5;">
                IMAGE
                <td>
                    <img class="workPicture" src="images/aff_single.jpg" alt="Affordances in RL">
                </td>

                TITLE AND INFO
                <td>
                    <br>
                    <div id="indexWorkText">
                        Title + Link
                        <b><a href="https://arxiv.org/pdf/2006.15085.pdf" onclick="_gaq.push(['_trackEvent', 'Click', 'Affordance Paper Clicked']);">What can I do here? A Theory of Affordances in Reinforcement Learning</a></b>
                        <br>
                        <i>ICML 2020</i>
                    </div>
                    <br>
                    One sentence description
                    <div id="indexWorkText">
                        We develop a theory of <a href="https://en.wikipedia.org/wiki/Affordance">affordances</a> in the context of RL and planning.
                    </div>
                    <br>

                    Collaborators
                    <div id="indexWorkText">
                        Led by <a href="https://kkhetarpal.github.io/">Khimya Khetarpal</a>, joint with <a href="http://www.zafarali.me/">Zafarali Ahmed</a>, <a href="https://scholar.google.com/citations?user=CiUedsUAAAAJ&amp;hl=en">Gheorghe Comanici</a>, and <a href="https://www.cs.mcgill.ca/~dprecup/">Doina Precup</a>.
                    </div>
                    <br>
                    <br>
                </td>
            </tr>

            Work
            <tr style="border-bottom:1px solid #e5e5e5;">
                IMAGE
                <td>
                    <img class="workPicture" src="images/p2pc.jpg" alt="Planned Information Processing">
                </td>

                TITLE AND INFO
                <td>
                    <br>
                    <div id="indexWorkText">
                        Title + Link
                        <b><a href="papers/aaai2020_plan_to_plan.pdf" onclick="_gaq.push(['_trackEvent', 'Click', 'Plan-to-Plan Paper Clicked']);">The Efficiency of Human Cognition Reflects Planned Use of Information Processing</a></b>
                        <br>
                        <i>AAAI 2020</i>
                    </div>
                    <br>
                    One sentence description
                    <div id="indexWorkText">
                        We develop a model that characterizes the planned use of information processing as a meta-reasoning problem and study this model's capacity to predict human reaction times in simple tasks.
                    </div>
                    <br>

                    Collaborators
                    <div id="indexWorkText">
                        By <a href="https://markkho.github.io">Mark K. Ho</a>, <a href="https://webapps.pni.princeton.edu/ncc/JDC/Home_Page.html">Jonathan D. Cohen</a>, <a href="http://cs.brown.edu/~mlittman/">Michael L. Littman</a>, <a href="http://cocosci.princeton.edu/tom/index.php">Thomas L. Griffiths</a>.
                    </div>
                    <br>
                    <br>
                </td>
            </tr>

            Work
            <tr style="border-bottom:1px solid #e5e5e5;">
                IMAGE
                <td>
                    <img class="workPicture" src="images/voa4.jpg" alt="The process of abstraction">
                </td>

                TITLE AND INFO
                <td>
                    <br>
                    <div id="indexWorkText">
                        Title + Link
                        <b><a href="papers/cobs2019_value_of_abstr.pdf" onclick="_gaq.push(['_trackEvent', 'Click', 'Plan-to-Plan Paper Clicked']);">The Value of Abstraction</a></b>
                        <br>
                        <i>Current Opinions in Behavioral Science 2019</i>
                    </div>
                    <br>
                    One sentence description
                    <div id="indexWorkText">
                        We discuss the vital role that abstraction plays in efficient decision making.
                    </div>
                    <br>

                    Collaborators
                    <div id="indexWorkText">
                        Led by <a href="https://markkho.github.io">Mark K. Ho</a>, joint with <a href="http://cs.brown.edu/~mlittman/">Michael L. Littman</a>, <a href="http://cocosci.princeton.edu/tom/index.php">Thomas L. Griffiths</a>.
                    </div>
                    <br>
                    <br>
                </td>
            </tr>


            Work 2
            <tr style="border-bottom:1px solid #e5e5e5;">
                IMAGE
                <td>
                        <img class="workPicture" src="images/elm.jpg" alt="Expected-Length Option Model">
                </td>

                TITLE AND INFO
                <td>
                    <br>
                    <div id="indexWorkText">
                        Title + Link
                        <b><a href="papers/elm_options_19.pdf" onclick="_gaq.push(['_trackEvent', 'Click', 'ELM Options Paper Clicked']);">The Expected-Length Model of Options </a></b>
                        <br>
                        <i>IJCAI 2019</i>
                    </div>
                    <br>
                    One sentence description
                    <div id="indexWorkText">
                        We introduce and motivate the Expected-Length Model of Options, a simpler alternative for characterizing the transition and reward functions of options.
                    </div>
                    <br>

                    Collaborators
                    <div id="indexWorkText">
                        Joint with <a href="https://github.com/jwinder1">John Winder</a>, <a href="https://www.csee.umbc.edu/~mariedj/">Marie desJardins</a>, and <a href="http://cs.brown.edu/~mlittman/">Michael L. Littman</a>.
                    </div>
                    <br>
                    <br>
                </td>
            </tr>



            Work 2
            <tr style="border-bottom:1px solid #e5e5e5;">
                IMAGE
                <td>
                    <img class="workPicture" src="images/rlit.jpg" alt="State Abstr for Lifelong RL">
                </td>

                TITLE AND INFO
                <td>
                    <br>
                    <div id="indexWorkText">
                        Title + Link
                        <b><a href="papers/rlit_aaai_2019.pdf" onclick="_gaq.push(['_trackEvent', 'Click', 'RLIT AAAI Paper Clicked']);">State Abstraction as Compression in Apprenticeship Learning</a></b>
                        <br>
                        <i>AAAI 2019</i>
                    </div>
                    <br>

                    One sentence description
                    <div id="indexWorkText">
                        We study state abstractions that trade-off between compression and optimality through rate-distortion theory.
                    </div>
                    <br>

                    Collaborators
                    <div id="indexWorkText">
                        Joint work with <a href="http://dilipa.github.io/">Dilip Arumugam</a>, <a href="http://cs.brown.edu/people/kasadiat/">Kavosh Asadi</a>, <a href="https://jinnaiyuu.github.io/">Yuu Jinnai</a>, <a href="http://cs.brown.edu/~mlittman/">Michael L. Littman</a>, and <a href="https://www.ccis.northeastern.edu/people/lawson-wong/">Lawson L.S. Wong</a>.
                    </div>
                    <br>
                    <br>
                </td>
            </tr>


            Work 2
            <tr style="border-bottom:1px solid #e5e5e5;">
                IMAGE
                <td>
                    <img class="workPicture" src="images/point_opt.jpg" alt="Point Options">
                </td>

                TITLE AND INFO
                <td>
                    <br>
                    <div id="indexWorkText">
                        Title + Link
                        <b><a href="papers/finding_options_icml_19.pdf" onclick="_gaq.push(['_trackEvent', 'Click', 'Options-Planning Paper Clicked']);">Finding Options that Minimize Planning Time </a></b>
                        <br>
                        <i>ICML 2019</i>
                    </div>
                    <br>
                    One sentence description
                    <div id="indexWorkText">
                        We prove that the problem of finding options that minimize planning time is NP-Hard.
                    </div>
                    <br>

                    Collaborators
                    <div id="indexWorkText">
                        Led by <a href="https://jinnaiyuu.github.io/">Yuu Jinnai</a>, joint with <a href="https://dhershko.github.io/">D Ellis Hershkowitz</a>, <a href="http://cs.brown.edu/~mlittman/">Michael L. Littman</a>, and <a href="http://cs.brown.edu/people/gdk/">George Konidaris</a>.
                    </div>
                    <br>
                    <br>
                </td>
            </tr>

            
        </tbody></table>



        FOOTER
        		
		<p style="line-height: 1.2;" align="middle"><medium>Theme <a href="https://github.com/david-abel/minimal">based</a> on <a href="https://github.com/orderedlist/minimal">minimal</a> by <a href="https://github.com/orderedlist">orderedlist</a><br>
		Copyright <a href="https://malradhi.github.io/">Dr. Mohammed Salah Al-Radhi</a> <script>document.write(new Date().getFullYear())</script></medium></p>

      </section>
	   
	  	
    </div>
-->	


<!-- 
<footer>
    <p id="timeDisplay"></p>
  </footer>

  <script>
    // Function to get local time
    function getLocalTime() {
      const date = new Date();
      const timeString = date.toLocaleTimeString([], {hour: '2-digit', minute: '2-digit'});
      const dateString = date.toLocaleDateString([], {day: '2-digit', month: 'short'});
      return `<strong>Your Time:</strong> ${timeString}, ${dateString}`;
    }

    // Function to get site time
    function getSiteTime() {
      // Replace 'https://malradhi.github.io/' with the actual URL of the site
      fetch('https://malradhi.github.io/')
        .then(response => response.headers.get('date'))
        .then(dateTimeString => {
          if(dateTimeString) {
            const date = new Date(dateTimeString);
            const timeString = date.toLocaleTimeString([], {hour: '2-digit', minute: '2-digit'});
            const dateString = date.toLocaleDateString([], {day: '2-digit', month: 'short'});
            document.getElementById('timeDisplay').innerHTML = `<strong>Your Time:</strong> ${getLocalTime()} â€¢ <strong>Site Time:</strong> ${timeString}, ${dateString}`;
          } else {
            console.error('Site time unavailable');
            document.getElementById('timeDisplay').innerHTML = `<strong>Your Time:</strong> ${getLocalTime()} â€¢ <strong>Site Time:</strong> <em>Site time unavailable</em>`;
          }
        })
        .catch(error => {
          console.error('Error fetching site time:', error);
          document.getElementById('timeDisplay').innerHTML = `<strong>Your Time:</strong> ${getLocalTime()} â€¢ <strong>Site Time:</strong> <em>Site time unavailable</em>`;
        });
    }

    // Fetch site time once when the page loads
    window.onload = getSiteTime;
  </script>
 -->






</body></html> 

<!-- 
CITATION METRICS
According to GoogleSholar, my works attracted more than 130 citations, my h-index is 6, and my i10-index (number of papers with at least 10 citations) is 4. 
 -->
 